{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U langchain_community langchain langchain_huggingface langchain_openai\n",
    "# ! pip install openai\n",
    "#! pip install \"unstructured[all-docs]\"\n",
    "#! pip install langchain chromadb unstructured openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredEPubLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from markdown import markdown\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"<your_api_key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "pypandoc.download_pandoc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ce niveau, certains packages doivent être présent en local, sous linux, il faut installer **pandoc** (sudo apt install pandoc)\n",
    "\n",
    "Ou \n",
    "\n",
    "import pypandoc <br>\n",
    "pypandoc.download_pandoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_store(path):\n",
    "    loader = UnstructuredEPubLoader(path)\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=10\n",
    "    )\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    vectorStore = Chroma.from_documents(documents, embeddings)\n",
    "    return vectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _llm(question, context):\n",
    "    formatted_prompt = f\"question: {question}\\n\\n context: {context}\"\n",
    "    \n",
    "    # model = AzureChatOpenAI(\n",
    "    #     azure_deployment=\"gpt-35-turbo-16k\",\n",
    "    #     api_version=\"2023-06-01-preview\",\n",
    "    # )\n",
    "    # message = [{\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": formatted_prompt\n",
    "    # }]\n",
    "    # return model.invoke(message).content\n",
    "\n",
    "    response = \"\"\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"{formatted_prompt}\"\n",
    "            }],\n",
    "        stream=True,\n",
    "    )\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            response += chunk.choices[0].delta.content\n",
    "            \n",
    "    return response\n",
    "\n",
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def rag_chain(question, vectorStore):\n",
    "    retriever = vectorStore.as_retriever()\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = combine_docs(retrieved_docs)\n",
    "    return _llm(question, formatted_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epub_path = \"docs/39419251_rtl.epub\"\n",
    "vectorStore = vector_store(epub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"talk me about document\"\n",
    "response = markdown(rag_chain(question, vectorStore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
